---
title: "Homework 5"
output:
  pdf_document: 
    latex_engine: xelatex
  html_document:
    df_print: paged
date: "`r Sys.Date()`"
subtitle: Due Wednesday Nov 4, 2020
---

```{r setup, include=FALSE}
knitr::opts_chunk$set(echo = TRUE)
```

For each assignment, turn in by the due date/time.  Late assignments must be arranged prior to submission.  In every case, assignments are to be typed neatly using proper English in Markdown.  

This week, we spoke about Exploratory Data Analysis and plotting. To begin the homework, we will as usual, start by loading, munging and  creating tidy data sets.  In this homework, our goal is to create informative (and perhaps pretty) plots showing features or perhaps deficiencies in the data.

## Problem 1

Work through the Swirl "Exploratory_Data_Analysis" lesson parts 1 - 10.  If you need some review of ggplot, see the tutorial on Rstudio.cloud.

\textbf{I took above lessons.}

## Problem 2

Create a new R Markdown file within your local GitHub repo folder (file-->new-->R Markdown-->save as).

The filename should be: HW5_lastname, i.e. for me it would be HW5_Settlage

You will use this new R Markdown file to solve the following problems.

## Problem 3

Using tidy concepts, get and clean the following data on education from the World Bank.

<http://databank.worldbank.org/data/download/Edstats_csv.zip>

How many data points were there in the complete dataset?  In your cleaned dataset?

Choosing 2 countries, create a summary table of indicators for comparison.

```{r}
library(tidyr)
library(tidyverse)
library(knitr)

# Import Data
setwd("~/STAT5014_youngjin/Edstats_csv")
eco_data <- read.csv("EdStatsData.csv",skip=1,header=FALSE)

# V70 is just blank column
# So I removed it
summary(eco_data$V70)
eco_data <- eco_data[,-70]

# Assign column names
colnames(eco_data) <- c("Country Name","Country Code","Indicator Name","Indicator Code",
                        1970:2017,seq(2020,2100,by=5))
colnames(eco_data)

# There are so many countries and so many indicators
# I choose France and United Kingdom for comparison
# I will use first 2 indicators for comparison between France and United Kingdom
length(unique(eco_data$`Country Name`))
head(unique(eco_data$`Country Name`),10)
length(unique(eco_data$`Indicator Name`))
head(unique(eco_data$`Indicator Name`),10)

# Filtering data
eco_data_f <- head(eco_data %>% subset(`Country Name`=='France'),2)
eco_data_u <- head(eco_data %>% subset(`Country Name`=='United Kingdom'),2)
eco_data_f_u <- rbind(eco_data_f,eco_data_u)
eco_data_f_u <- eco_data_f_u[,-c(2,4)]

# Making summary statistics
eco_data_f_u_summary <- data.frame(eco_data_f_u[,1:2],matrix(NA,4,6))
colnames(eco_data_f_u_summary)[3:8] <- c("Min","1st Qu.","Median","Mean","3rd Qu.","Max.")
eco_data_f_u_summary[1,3:8] <- summary(as.numeric((eco_data_f_u[1,-c(1,2)])))[-7]
eco_data_f_u_summary[2,3:8] <- summary(as.numeric((eco_data_f_u[2,-c(1,2)])))[-7]
eco_data_f_u_summary[3,3:8] <- summary(as.numeric((eco_data_f_u[3,-c(1,2)])))[-7]
eco_data_f_u_summary[4,3:8] <- summary(as.numeric((eco_data_f_u[4,-c(1,2)])))[-7]

# Making summary table
eco_data_f_u_summary <- gather(eco_data_f_u_summary,key="statistic",value="value","Min","1st Qu.","Median","Mean","3rd Qu.","Max.")
eco_data_f_u_summary <- spread(data=eco_data_f_u_summary,key="Country.Name",value='value')

# Summary table
kable(eco_data_f_u_summary,caption = "Comparison between France and United Kingdom")

# The number of data points in original data set
nrow(eco_data)
# The number of data points in filtered data set
nrow(eco_data_f_u)
```

In the orginal data set, threre are 886,930 data points. But in my cleaned data set, since I selected two countries and two indices, there are 4 data points.

## Problem 4

Using *base* plotting functions, create a single figure that is composed of the first two rows of plots from SAS's simple linear regression diagnostics as shown here: <https://support.sas.com/rnd/app/ODSGraphics/examples/reg.html>.  Demonstrate the plot using suitable data from problem 3.

```{r}
# Regression Data
# For France, I used UIS.NERA.2 (y) and UIS.NERA.2.F (x) for regression data
# NA values are removed
reg_data <- na.omit(data.frame(as.numeric(eco_data_f[1,]),as.numeric(eco_data_f[2,])))
colnames(reg_data) <- c("UIS.NERA.2","UIS.NERA.2.F")
head(reg_data)

# Regression fit
lmfit <- lm(reg_data[,1]~reg_data[,2])
```


```{r}
library(MASS)
library(sur)

# Function
diagnotistics <- function(lmfit, reg_data){
  par(mfrow=c(2,3))
  
  plot(lmfit$fitted.values,lmfit$residuals,xlab="Predicted Value", ylab="Residual")
  abline(h=0)
  
  plot(lmfit$fitted.values,studres(lmfit),xlab="Predicted Value", ylab="RStudent")
  abline(h=2)
  abline(h=-2)
  
  plot(leverage(lmfit),studres(lmfit),xlab="Leverage", ylab="RStudent")
  abline(h=2)
  abline(h=-2)

  qqnorm(lmfit$residuals, xlab="Quantile",ylab="Residual",main="")
  qqline(lmfit$residuals)

  plot(lmfit$fitted.values,reg_data$UIS.NERA.2,xlab="Predicted Value", ylab=colnames(reg_data)[1])
  abline(0,1)

  plot(1:nrow(reg_data),cooks.distance(lmfit),xlab="Observation",ylab="Cook's D",type=c("h"))
  points(1:nrow(reg_data),cooks.distance(lmfit))
}

# Plot
diagnotistics(lmfit, reg_data)
```

## Problem 5

Recreate the plot in problem 3 using ggplot2 functions.  Note: there are many extension libraries for ggplot, you will probably find an extension to the ggplot2 functionality will do exactly what you want.

```{r}
require(gridExtra)

fit_res <- data.frame(lmfit$fitted.values,lmfit$residuals)
names(fit_res) <- c("fit","res")
fit_stu <- data.frame(lmfit$fitted.values,studres(lmfit))
names(fit_stu) <- c("fit","stu")
lev_stu <- data.frame(leverage(lmfit),studres(lmfit))
names(lev_stu) <- c("lev","stu")
res <- data.frame(y = lmfit$residuals)
fit_y <- data.frame(lmfit$fitted.values,reg_data$UIS.NERA.2)
names(fit_y) <- c("fit","y")
obs_cook <- data.frame(1:nrow(reg_data),cooks.distance(lmfit))
names(obs_cook) <- c("obs","cook")

plot1 <- ggplot(fit_res, aes(fit, res)) + geom_point(size = 0.5) + labs(y = "Residual", x="Predicted Value") + geom_hline(yintercept=0)
plot2 <- ggplot(fit_stu, aes(fit, stu)) + geom_point(size = 0.5) + labs(y = "Rstudent", x="Predicted Value") + geom_hline(yintercept=2) + geom_hline(yintercept=-2)
plot3 <- ggplot(lev_stu, aes(lev, stu)) + geom_point(size = 0.5) + labs(y = "Rstudent", x="Leverage") + geom_hline(yintercept=2) + geom_hline(yintercept=-2)
plot4 <- ggplot(res, aes(sample = y)) + stat_qq(size = 0.5) + stat_qq_line() + labs(y = "Residual", x = "Quantile")
plot5 <- ggplot(fit_y, aes(fit, y)) + geom_point(size = 0.5) + labs(y = "UIS.NERA.2", x="Predicted Value") + geom_abline(intercept = 0, slope = 1)
plot6 <- ggplot(obs_cook, aes(x=obs, y=cook)) + geom_point(size = 0.5) + labs(y = "Cook's D", x="Observation") + geom_segment( aes(x=obs, xend=obs, y=0, yend=cook))

grid.arrange(plot1, plot2, plot3, plot4, plot5, plot6, ncol=3, nrow=2)
```


## Problem 6

Finish this homework by pushing your changes to your repo.

**Only submit the .Rmd and .pdf solution files.  Names should be formatted HW5_lastname_firstname.Rmd and HW5_lastname_firstname.pdf**